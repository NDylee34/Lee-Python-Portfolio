# Lee-Python-Portfolio

This portfolio is a compilation of all the **Elements of Computing II projects** I have worked on this semester. It is regularly updated to showcase **data analysis, visualization, and interactive applications** using Python.

## ğŸ“Œ Projects

### **Streamlit App**
ğŸ”— [View Project Repository](https://github.com/NDylee34/Lee-Python-Portfolio/tree/main/basic-streamlit-app)

**Description:**  
The **Streamlit App** is an **interactive web application** that allows users to **explore data about penguins inhabiting different islands**. The app:

âœ” Loads **penguin dataset** from a CSV file.  
âœ” Displays **a searchable and filterable table**.  
âœ” Allows users to **filter data by island using a dropdown menu**.  
âœ” Uses **Streamlit** to create a **dynamic and user-friendly web interface**.

**Refinements to Improve the App:**  
âœ… Enhance user experience by **adding data visualizations** (e.g., distribution of species).  
âœ… Implement **dynamic filtering** for multiple columns.  
âœ… Improve the UI with **Streamlit styling options**.

### **Tidy Data Project**
ğŸ”— [View Project Repository](https://github.com/NDylee34/Lee-Python-Portfolio/tree/main/TidyData-Project)

**Description:**  
The **Tidy Data Project** applies **tidy data principles** to transform and analyze a dataset of **2008 Olympics medalists**. This project involves:

âœ” **Data Cleaning & Reshaping** â€“ Converting the dataset into a **structured format**.  
âœ” **Exploratory Data Analysis** â€“ Identifying trends in **gender distribution, medal counts, and country rankings**.  
âœ” **Advanced Visualizations** â€“ Creating **bar charts, boxplots, and pivot tables** to **deepen insights**.  

**How It Complements My Portfolio:**  
This project **showcases my ability to efficiently process and analyze unstructured data**, transforming it into a structured format that facilitates deeper insights. By applying tidy data principles, I ensure that the data is **clean, well-organized, and optimized** for analysis. Additionally, I **leverage data visualization techniques** to create compelling and meaningful representations that effectively highlight **trends, patterns, and relationships** within large datasets. Through this approach, I demonstrate my proficiency in making data-driven insights accessible and impactful.

You're right! Here's the same emoji-enhanced section delivered in plain text for **easy copy-paste** into your `.Rmd` or `README.md` file â€” no formatting issues:

### **Named Entity Recognition (NER) Streamlit App**  
ğŸ”— [View Project Repository](https://github.com/NDylee34/Lee-Python-Portfolio/tree/main/NERStreamlitApp)  
ğŸš€ [Launch Live App](https://lee-ner.streamlit.app/)

**Description:**  
The **NER Streamlit App** is a fully interactive web application that enables users to perform **custom rule-based Named Entity Recognition (NER)** using **spaCy**. Designed for flexibility and ease of use, the app allows users to:

âœ” **Upload or Input Custom Text** â€“ Analyze any document by uploading `.txt` files or entering text directly.  
âœ” **Define Custom Entity Labels & Patterns** â€“ Use spaCyâ€™s `EntityRuler` to create custom rules for identifying names, organizations, or key terms.  
âœ” **Visualize Results Instantly** â€“ View entities in both a labeled table and a live text highlight using spaCyâ€™s `displacy`.  
âœ” **Fully Cloud-Hosted** â€“ Deployed via **Streamlit Community Cloud** for public access and sharing.

**How It Complements My Portfolio:**  
This project showcases my ability to combine **natural language processing**, **interactive web development**, and **cloud deployment** into one cohesive, user-friendly product. It highlights my strengths in:

- ğŸ§© **Rule-based NLP** and custom pattern design using spaCy  
- ğŸ§‘â€ğŸ’» **Streamlit development** for interactive interfaces  
- ğŸ“¨ **User input handling** and real-time content generation  
- â˜ï¸ **Deployment to Streamlit Cloud** for accessibility and product-readiness

In the context of my broader portfolio, this app reflects my skill in building tools that are **functionally reliable** and **accessible to non-technical users**. It adds a new layer to my work in data analysis by incorporating **text processing, pattern recognition, and frontend user experience**, demonstrating my technical ability across the data pipeline.